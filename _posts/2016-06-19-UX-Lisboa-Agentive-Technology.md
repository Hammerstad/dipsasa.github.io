---
layout: post
title: "Hvordan designe for agentteknologi?"
author: lao
tags: [UXLx, UX, Brukeropplevelse, Konferanse, Beslutningsstøtte, Automatisering]
---

En av de mest inspirerende workshopene vi deltok på under [UX Lx i Lisboa](https://www.ux-lx.com/), var [workshopen til Chris Noessel](https://www.ux-lx.com/speakers/chris_noessel.html#workshop) om Designing for Agentive Technology.

Den ultimate brukeropplevelsen blir ofte omtalt som et grensesnitt som krever minimalt fra brukeren: null klikk. Med Agentive Technology kan vi som brukere lene oss tilbake og la teknologien utføre stadig mere komplekse oppgaver for oss. Vi blir dermed *ledere* av oppgavene fremfor oppgaveutførere. For oss designere medfører det at vi må tenke annerledes når vi designer produkter og tjenester.

![Chris Noessel](../../../img/lao/chris.jpg) 

<!--more-->

Dersom du skal designe et system for å bestille ferie, kunne vi gått frem på følgende måter:


- Manuel system hvor du selv må søke, bestille, betale og hente ut billetter
- Assisterende system som kommer med forslag til deg basert på for eksempel dine preferanser, populære turer og hva andre som likner på deg har bestilt, samt epost og SMS-varsel når det er gode tilbud som matcher det du er interessert i
- Agentsystem som automatisk bestiller turen for deg når den matcher kriteriene du har satt opp, samt automatisk betaler og henter ut billettene for deg

Forskjellen mellom assisterende teknologi og agentteknologi, er at førstnevnte hjelper deg med å utføre oppgaven eller nå målet, mens agentteknologi faktisk kan utføre oppgaven for deg. 
Agentteknologi blir dermed en slags lavnivå kunstig intelligens som fungerer som en agent på brukerens vegne for å utføre oppgaver. Dette er nyttig for oppgaver som vi ikke ønsker å gjøre eller som vi mener maskiner kan gjøre bedre. Dette er egentlig ikke en ny teknologi siden vi lenge har hatt automatisering av oppgaver, autopilot på fly og cruise control i biler, men bredden og omfanget vi nå ser det i er ny. I mangel på et bedre ord på norsk, kommer jeg derfor til å fortsette å bruke begrepet «agentsystem» og «agent» gjennom hele artikkelen. Chris Noessel omtaler det samme begrepet som «agentive technology» eller bare «agent». 

# Eksempler

For å forklare konseptet brukte Chris en del eksempler fra fysiske produkter, men også programvare.

**Narrative Clip**

Dette er [et lite kamera ](http://thenextweb.com/gadgets/2014/02/14/narrative-clip-review/#gref)som du enkelt fester til skjorten, og så tar det bilde hvert 30. sekund for å skape en visuell dagbok av en dag i livet ditt. Kameraet kan ta bilder manuelt dersom du trykker på det.
Bildene lastes så opp i skyen, og deretter kjøres det forskjellige algoritmer for å organisere bilder som hører sammen (spiser frokost, sitter på trikken, møte på jobben, fotballtrening osv). Deretter plukker applikasjonen ut de mest interessante bildene basert på en rekke faktorer. 
Til slutt får du en oversikt over de beste bildene i løpet av dagen, med så å si null tastetrykk. Du slipper å ta bilder manuelt eller gå gjennom bildene for å finne ut hvilke bilder som ble verdt å ta vare på. Dette produktet er derfor et eksempel på en agent.

![The Narrative Clip](../../../img/lao/The-Narrative-Clip.jpg)


**Roomba**

Et annet godt eksempel på «agentteknologi" er robotstøvsugeren [Roomba](http://www.irobot.com/For-the-Home/Vacuuming/Roomba.aspx). Robotstøvsugeren ser veldig annerledes ut enn tradisjonelle støvsugere. Den trenger ikke noe skaft å holde i, fordi den gjør all støvsugingen selv. Ved hjelp av algoritmer og sensorer vet støvsugeren hvor den skal støvsuge og den har full kontroll på hvor den er i huset. Dersom den må lade, kjører den tilbake til ladestasjonen og fortsetter støvsugingen når den er ferdigladet. Dersom støvsugeren kjører seg fast inn i et hjørne må du kanskje hjelpe den, men ellers er den så å si selvhjulpen. Teknologien er kanskje litt skummel eller føles unødvendig for enkelte, men hvem vil vel gå tilbake til å støvsuge når man først har fått en robot som kan gjøre jobben for deg?

![Roomba robotstøvsuger](../../../img/lao/irobot-roomba-560.jpg)

**Googles selvkjørende bil**

Både Google og Tesla forsker på [selvkjørende biler](https://www.google.com/selfdrivingcar/). Selvkjørende biler kan gi personer med synsutfordringer eller eldre mulighet til å komme seg rundt på egen hånd og dermed økt frihetsfølelse. Mange føler det er utenkelig at biler skal kunne kjøre uten sjåfører, men en gang i fremtiden mener foredragsholderen at det kanskje blir utenkelig å skjønne hvorfor vi noen gang har kjørt selv. Google hevder at så mye som 94% av dødsulykker hvor biler er involvert, skyldes menneskelig feil. Enkelte oppgaver kan kanskje med fordel overtas av maskiner som raskere kan reagere på omgivelsene rundt seg, og dermed skape en tryggere hverdag. 

Selvkjørende biler er eksempler på agentteknologi, men dersom det skulle skje en feil og bilen ikke lengre skulle kunne kjøre automatisk, bør den likevel kunne settes i manuelt modus og kjøres videre med, så fremst det er trygt. Bilkjøring er en ferdighet som vi må øve på, og holde ved like. Dersom vi ikke har kjørt på en lang stund eller er utrygge i trafikken kan vi skape farlige situasjoner, så det gjøres også tester på om disse bilene må kjøres manuelt innimellom slik at vi ikke glemmer hvordan vi kjører bil manuelt.

![Google's selvkjørende bil](../../../img/lao/google-self-driving-car-prototype-front-three-quarters-1.jpg)


**iOS Autocorrect**

Autokorrektur er en nyttig liten funksjon som hjelper deg med å stave ordet riktig og skrive raskere (selv om det finnes eksempler på det motsatte). 
Ordene kommer som forslag, men du har mulighet til å velge å ikke bruke forslaget. Dette er derfor et eksempel på en assisterende teknologi. Den er til hjelp, men den gjør ikke jobben for deg. 

![iOS Autocorrect](../../../img/lao/autocorrect.png)

**Waze**

Dette er en trafikkapplikasjon som i sanntid hjelper deg med å finne de mest effektive rutene basert på brukerinput fra andre trafikanter. På denne måten kan du derfor få varsler om politi, ulykker, veisperringer og trafikkork på forhånd, før du står midt oppi det.
Dette et godt eksempel på en applikasjon som er både agent og assisterende. Du får forslag til bedre trafikkruter uten å sjekke opp kart og trafikkmeldinger manuelt, og du kan selv velge hvilken vei du vil dra.  

![Waze](../../../img/lao/waze2.jpg)

**Spotify Discover Weekly**

Automatiske musikkanbefalinger er langt fra ny, men Spotify har klart å tilby anbefalinger som virker personlige og relevante. Når du tar i bruk Spotify må du sette opp en rekke preferanser for hvilken musikk og artister du liker å høre. Etter hvert som du har brukt Spotify en stund, vil den lære deg å kjenne. Hovedingrediensen i Discover Weekly anbefalingsalgoritmen er spillelistene og lyttevanene til andre brukere og deg selv. Basert på dette klarer den å komme med relevante anbefalinger til deg. Dersom det skulle være en sang som du ikke liker, tar Spotify ekstra hensyn til dette og lærer av det. For mer dyptgående informasjon om hvordan Spotify sine algoritmer fungerer, anbefales [denne bloggposten](http://qz.com/571007/the-magic-that-makes-spotifys-discover-weekly-playlists-so-damn-good/). 

Spotify er derfor et eksempel på en teknologi som først er assisterende i og med at den hjelper deg med å lage spillelister og finne musikk, men etter hvert blir tjenesten mer og mer agent siden den lærer deg å kjenne og du slipper å lete etter ny musikk fordi forslagene kommer automatisk til deg.

# Designe for agentteknologi
Overvåkning av datastrøm, følge med på triggere, samt regler og unntak er derfor viktige hensyn som må tas når du designer for både assisterende og agentteknologi. 

**Setupfase**

Enkle agenter kan bare skrus på og så starter de, men mer sofistikerte agenter må konfigureres og settes opp på en enkel og brukervennlig måte. 

- Forstå brukerens mål og preferanser: Hvordan kan agenten lære hva brukeren vil og hvordan den liker å få oppgaven utført? 
- Tilgang og autorisasjon: Hvordan bygger agenten opp nok tillit til at du vil gi den tilgang til informasjon slik at den blir i stand til å gjøre jobben sin?
- Testkjøring: Hvordan kan brukeren teste ut agenten for å se at den er satt opp riktig og vil fungere som tenkt?
- Lansering: Hvordan starter brukeren agenten, og vil brukeren være trygg på at agenten jobber?
- Distribuert tilpasning: Hvor mye tilpasning må brukeren gjøre på forhånd, og hvor mye kan vi avvente til senere med?

**Se hva agenten gjør**

Når agenten virker, vil brukeren få maks utbytte med minimalt med anstrengelser. Som en designer må du tenke på følgende situasjoner:

- Pause og restart: Hvordan kan brukeren sette agenten på vent og så starte den igjen?
- Monitorering: Når agenten er ny, er det spesielt viktig å kunne sjekke hvordan agenten har det. Utfører den jobben sin på en god måte?
- Lek: Enkelte brukere syns det er morsomt å leke ved siden av agenten. Det kan være for å øve seg og holde ferdigheter ved like, håndtere situasjoner som agenten ikke takler, eller rett og slett vinne over agenten. 
- Notifikasjoner: Hvordan skal brukeren vite at agenten jobber, når oppgaver er utført eller det har oppstått situasjoner?

**Håndtere unntak**

Det er fristende å tenke at unntak sjeldent oppstår og tenke på dem som sekundært. Men, ifølge foredragsholderen så er unntak noe av det viktigste vi må ta hensyn til, fordi det er da brukeren er mest involvert med agenten. Dersom agenten ikke degraderer på en god måte, kan det medføre at brukeren mister tillitt til produktet og stopper å bruke den. 

- Begrensede ressurser: Hvordan gir agenten signal om at den er i ferd med å gå tom for f. eks batteri eller andre ting den trenger for å kjøre? Kan agenten selv skaffe seg ressursene den trenger?
- «Edge case» notifikasjoner: Hva gjør agenten dersom den reagerer på ting den ikke bør, eller ikke reagerer på ting den bør reagere på? Kan brukeren hjelpe agenten dersom den står fast? Kan agenten lære av feilene den gjør?
- Frakopling og død: Hva skal agenten gjøre dersom den lever lengre enn brukerne sine? Skal kontrollen kunne overføres til andre? Hvordan skal denne overleveringen fungere? Eller skal agenten gå over i dvalemodus, og hvordan skal den eventuelt kunne vekkes igjen?

**Overlevering av kontroll**

Som vi så i eksemplet med selvkjørende biler, så kan bruk av agentteknologi medføre at vi mister evnene våre til å utføre oppgaven. Når vi designer denne type teknologi er det derfor noen hensyn som må ivaretas:


- Hvordan kan kontroll overføres fra agenten til brukeren, og omvendt?
- Hvordan tilrettelegger systemet for øvelse? Kan agenten gi deg noe støtte og hjelp selv om du må håndtere oppgaven manuelt dersom du trenger det?
- Hvordan kan agenten advare brukeren om at han eller hun må ta over systemet en stund? 
- Bør agenten ta tilbake kontrollen så fort den er i stand til det, eller bør det være en manuell overleveringsprosess?

**Skape tillit**

Det er viktig å kunne se under panseret for å skjønne hva som skjer og skape tillit til systemet. Dette er spesielt viktig når det er ny teknologi og du ikke helt skjønner hvordan systemet fungerer. 

# Relatert til egen arbeidshverdag og DIPS

For å relatere dette til egen arbeidshverdag, så syns jeg dette er et relevant og spennende tema siden DIPS ASA lager systemer som skal gjøre arbeidshverdagen til leger, sykepleiere og kontorpersonell enklere og mer effektiv.
Dette kan være alt fra bedre planleggingsverktøy i forbindelse med tildeling av timer på poliklinikk, eller hvordan man fordeler operasjonsstuer og operasjonspersonell for å utnytte begrensede ressurser på en mer optimal måte slik at ventetiden på operasjoner går ned. En god planleggingskabal kan være tidkrevende å lage manuelt siden du må lage deg en oversikt over alle pasienter som skal inn til en operasjonstype innenfor et gitt tidsintervall, og du må ta hensyn til fasetter som operasjonstype, operasjonstid, ressurser (kirurg, anestesipersonell, operasjonssykepleier m.fl), operasjonssal, utstyr osv. Det er med andre ord mange fasetter som må settes opp mot hverandre. Gjennom AKTIV-prosjektet sammen med Sintef jobber ett av teamene i DIPS med et system som foreslår planer, slik at jobben til inntaksplanleggerne blir lettere. 

DIPS jobber også med **gjenbruk av data og automatisk utfylling** av data i journalen. Basert på hva du eller andre tidligere har fylt ut av informasjon i journalen eller fått inn av automatiske prøvesvar, kan helsepersonell spare tid på å slippe å plotte inn data manuelt i systemet. For sluttbrukeren er det viktig å ha kontroll og oversikt over hvor dataene er hentet fra, hvem som har registrert den og når tid registreringen ble gjort. Dette er spesielt viktig når systemet er uvant for brukerne, eller dersom feilsituasjoner skulle oppstå. 

Et tredje eksempel er **klinisk beslutningsstøtte**. Basert på data i pasientens journal og nasjonale retningslinjer for behandling, kan systemet komme med forslag til tiltak og beregne risiko i forbindelse med for eksempel slag og infeksjoner.

Dette er eksempler på assisterende teknologi, men i fremtiden når systemene blir gode nok har de potensiale til å bli mer som agenter. Dette krever at brukerne har stor tillitt til systemet og at systemet utfører jobben på en mer korrekt og effektiv måte enn det mennesker ville ha gjort.

# Mer om temaet
Jeg syns dette er et veldig spennende tema og jeg anbefaler dere derfor å følge [Chris Noessel](https://twitter.com/chrisnoessel) på Twitter og se [denne videoen](https://vimeo.com/144687906) som forklarer konseptet og bruker omtrent de samme eksemplene som jeg har videreformidlet i denne bloggposten.   


<iframe src="https://player.vimeo.com/video/144687906" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
<p><a href="https://vimeo.com/144687906">THE DAWN OF AGENTIVE TECHNOLOGY</a> from <a href="https://vimeo.com/user4280938">&Oslash;redev Conference</a> on <a href="https://vimeo.com">Vimeo</a>.</p>